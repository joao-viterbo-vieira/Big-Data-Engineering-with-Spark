{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28a3ac93",
   "metadata": {},
   "source": [
    "# Reading Parquet Files with Pandas\n",
    "\n",
    "This notebook demonstrates how to read multiple parquet files from a directory using pandas. This is primarily a test to determine if pandas can handle loading all 86 million rows from the data files. However, pandas either fails or takes an infeasible amount of time to process this volume of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840f22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dcdcdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 parquet files:\n",
      "- yellow_tripdata_2024-08.parquet\n",
      "- yellow_tripdata_2024-07.parquet\n",
      "- yellow_tripdata_2025-02.parquet\n",
      "- yellow_tripdata_2024-06.parquet\n",
      "- yellow_tripdata_2024-05.parquet\n",
      "- yellow_tripdata_2024-03.parquet\n",
      "- yellow_tripdata_2024-01.parquet\n",
      "- yellow_tripdata_2024-09.parquet\n",
      "- yellow_tripdata_2024-02.parquet\n",
      "- yellow_tripdata_2023-10.parquet\n",
      "- yellow_tripdata_2023-07.parquet\n",
      "- yellow_tripdata_2023-04.parquet\n",
      "- yellow_tripdata_2023-08.parquet\n",
      "- yellow_tripdata_2025-01.parquet\n",
      "- yellow_tripdata_2024-10.parquet\n",
      "- yellow_tripdata_2023-12.parquet\n",
      "- yellow_tripdata_2023-06.parquet\n",
      "- yellow_tripdata_2023-11.parquet\n",
      "- yellow_tripdata_2023-02.parquet\n",
      "- yellow_tripdata_2023-09.parquet\n",
      "- yellow_tripdata_2024-11.parquet\n",
      "- yellow_tripdata_2024-12.parquet\n",
      "- yellow_tripdata_2024-04.parquet\n",
      "- yellow_tripdata_2023-03.parquet\n",
      "- yellow_tripdata_2023-05.parquet\n",
      "- yellow_tripdata_2023-01.parquet\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the data directory\n",
    "data_dir = Path('data')\n",
    "\n",
    "# Get a list of all parquet files in the data directory\n",
    "parquet_files = glob.glob(str(data_dir / '*.parquet'))\n",
    "\n",
    "# Print the list of files found\n",
    "print(f\"Found {len(parquet_files)} parquet files:\")\n",
    "for file in parquet_files:\n",
    "    print(f\"- {os.path.basename(file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a2dac",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Function to read a single parquet file\n",
    "def read_parquet_file(file_path):\n",
    "    try:\n",
    "        df = pd.read_parquet(file_path)\n",
    "        print(f\"Successfully read {os.path.basename(file_path)} with {len(df)} rows and {len(df.columns)} columns\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {os.path.basename(file_path)}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1e1599",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parquet_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Read all parquet files into a dictionary\u001b[39;00m\n\u001b[32m      2\u001b[39m dataframes = {}\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mparquet_files\u001b[49m:\n\u001b[32m      5\u001b[39m     file_name = os.path.basename(file).replace(\u001b[33m'\u001b[39m\u001b[33m.parquet\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m     dataframes[file_name] = read_parquet_file(file)\n",
      "\u001b[31mNameError\u001b[39m: name 'parquet_files' is not defined"
     ]
    }
   ],
   "source": [
    "# Read all parquet files into a dictionary\n",
    "dataframes = {}\n",
    "\n",
    "for file in parquet_files:\n",
    "    file_name = os.path.basename(file).replace('.parquet', '')\n",
    "    dataframes[file_name] = read_parquet_file(file)\n",
    "\n",
    "print(f\"\\nLoaded {len([df for df in dataframes.values() if df is not None])} dataframes successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ae6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dataframes into one (if needed)\n",
    "if dataframes and any(df is not None for df in dataframes.values()):\n",
    "    try:\n",
    "        combined_df = pd.concat([df for df in dataframes.values() if df is not None])\n",
    "        print(f\"Combined dataframe shape: {combined_df.shape}\")\n",
    "        \n",
    "        # Display the first few rows of the combined dataframe\n",
    "        combined_df.head()\n",
    "    except Exception as e:\n",
    "        print(f\"Error combining dataframes: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87b85a9",
   "metadata": {},
   "source": [
    "## Exploring a Single Dataframe\n",
    "\n",
    "Let's take a closer look at one of the dataframes to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43fd4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first dataframe from our dictionary (if any exist)\n",
    "if dataframes and any(df is not None for df in dataframes.values()):\n",
    "    # Get the first non-None dataframe\n",
    "    first_key = next(key for key, df in dataframes.items() if df is not None)\n",
    "    first_df = dataframes[first_key]\n",
    "    \n",
    "    print(f\"Examining dataframe: {first_key}\")\n",
    "    print(f\"Shape: {first_df.shape}\")\n",
    "    print(\"\\nColumn information:\")\n",
    "    for col in first_df.columns:\n",
    "        print(f\"- {col}: {first_df[col].dtype}\")\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\nSummary statistics:\")\n",
    "    first_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
